{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Regularización\n",
    "\n",
    "![](images/portada_nb_FAV.png)\n",
    "\n",
    "## Módulo 6 - Aprendizaje de máquina supervisado\n",
    "### Profesor: M.Sc. Favio Vázquez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "La regularización ayuda a resolver el problema de sobreajuste en el aprendizaje automático. El modelo simple será una generalización de datos muy pobre. Al mismo tiempo, es posible que el modelo complejo no funcione bien en los datos de prueba debido a un ajuste excesivo. Necesitamos elegir el modelo correcto entre el modelo simple y el complejo. La regularización ayuda a elegir la complejidad del modelo preferido, de modo que el modelo predice mejor. La regularización no es más que agregar un término de penalización a la función objetivo y controlar la complejidad del modelo usando ese término de penalización. Se puede utilizar para muchos algoritmos de aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Parte 1: Sobreajuste\n",
    "\n",
    "**¿Qué es el sobreajuste?**\n",
    "\n",
    "- Construir un modelo que coincida con los datos de entrenamiento \"demasiado cerca\".\n",
    "- Aprendiendo del error / distorsión / ruido en los datos, en lugar de solo los valores / señal verdaderos.\n",
    "\n",
    "**¿Cómo se produce el sobreajuste?**\n",
    "\n",
    "- Evaluar un modelo probándolo con los mismos datos que se utilizaron para entrenarlo.\n",
    "- Creación de un modelo \"demasiado complejo\".\n",
    "\n",
    "**¿Cuál es el impacto del sobreajuste?**\n",
    "\n",
    "- El modelo funcionará bien en los datos de entrenamiento, pero no se generalizará a datos fuera de la muestra, es decir, prueba\n",
    "- El modelo tendrá un sesgo bajo, pero una varianza alta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Parte 2: Sobreajuste con modelos lineales\n",
    "\n",
    "**¿Cuáles son las características generales de los modelos lineales?**\n",
    "\n",
    "- Baja complejidad del modelo\n",
    "- Alto sesgo, baja varianza\n",
    "- Generalmente, no tiende a sobreajustarse\n",
    "\n",
    "siempre existe la posibilidad de **sobreajuste y aún puede ocurrir** con modelos lineales si les permite tener **alta varianza**. <br> Algunas causas comunes son:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### Causa 1: características irrelevantes\n",
    "\n",
    "Los modelos lineales pueden sobreajustarse si incluyen \"características irrelevantes\", es decir, características que no están relacionadas con la respuesta. ¿Por qué?\n",
    "\n",
    "Porque aprenderá un coeficiente para cada característica que incluir en el modelo, independientemente de si esa característica tiene el **impacto** o el **ruido**.\n",
    "\n",
    "Esto es especialmente un problema cuando **p (número de características) está cerca de n (número de observaciones)**, porque ese modelo naturalmente tendrá una alta varianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### Causa 2: características correlacionadas (muticolinealidad)\n",
    "\n",
    "Los modelos lineales pueden sobreajustarse si las características incluidas están altamente correlacionadas entre sí. ¿Por qué?\n",
    "\n",
    "Usamos el método OLS (Ordinary Least Squares) (OLS toma algunas suposiciones) [documentación de scikit-learn](http://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares):\n",
    "\n",
    "\"... las estimaciones de coeficientes para mínimos cuadrados ordinarios se basan en la independencia de los términos del modelo. Cuando los términos están correlacionados y las columnas de la matriz de diseño X tienen una dependencia lineal aproximada, la matriz de diseño se vuelve casi singular y como como resultado, la estimación de mínimos cuadrados se vuelve muy sensible a errores aleatorios en la respuesta observada, produciendo una gran varianza \"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### Causa 3: Coeficientes grandes\n",
    "\n",
    "Los modelos lineales pueden sobreajustarse si los coeficientes (después de la estandarización de características) son demasiado grandes. ¿Por qué?\n",
    "\n",
    "Debido a que **mayor** es el valor absoluto del coeficiente, más **potencia** tiene para cambiar la respuesta prevista, lo que da como resultado una varianza más alta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Parte 3: Regularización de modelos lineales\n",
    "\n",
    "- La regularización es un método para \"restringir\" o \"regularizar\" el tamaño **de los coeficientes**, y así \"reducirlos\" a cero.\n",
    "- Reduce la variación del modelo y, por lo tanto, **minimiza el sobreajuste**.\n",
    "- Si el modelo es demasiado complejo, tiende a reducir la varianza más de lo que aumenta el sesgo, lo que da como resultado un modelo que tiene **más probabilidades de generalizar**.\n",
    "\n",
    "Nuestro objetivo es localizar la **complejidad óptima del modelo**, por lo que la regularización es útil cuando creemos que nuestro modelo es demasiado complejo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bias-variance tradeoff](images/bias_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### ¿Cómo funciona la regularización?\n",
    "\n",
    "Para un modelo de regresión lineal normal, estimamos los coeficientes utilizando el criterio de mínimos cuadrados, que **minimiza la suma de cuadrados residual (RSS):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Estimating coefficients](images/estimating_coefficients.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Para un modelo de regresión lineal regularizado, **minimizamos la suma de RSS y un \"término de penalización\"** que penaliza el tamaño del coeficiente.\n",
    "\n",
    "**Ridge regression** (o \"regularización L2\") minimiza: $$\\text{RSS} + \\alpha \\sum_{j=1}^p \\beta_j^2$$\n",
    "\n",
    "**Lasso regression** (o \"regularización L1\") minimiza: $$\\text{RSS} + \\alpha \\sum_{j=1}^p |\\beta_j|$$\n",
    "\n",
    "- $p$ es el **número de características**\n",
    "- $\\beta_j$ es un **coeficiente del modelo**\n",
    "- $\\alpha$ es un **parámetro de ajuste:**\n",
    "    - Un pequeño $\\alpha$ no impone ninguna penalización en el tamaño del coeficiente y es equivalente a un modelo de regresión lineal normal.\n",
    "    - Incrementar el $\\alpha$ penaliza los coeficientes y por lo tanto los reduce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### Diagramas de ruta de Lasso y Ridge\n",
    "\n",
    "Un alfa más grande (hacia la izquierda de cada diagrama) da como resultado una mayor regularización:\n",
    "\n",
    "- **Regresión de Lasso** reduce los coeficientes hasta cero, eliminándolos del modelo\n",
    "- **Regresión de Ridge** reduce los coeficientes hacia cero, pero rara vez llegan a cero\n",
    "\n",
    "Código fuente para los diagramas: [Lasso Regression](http://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_lars.html) y [Ridge regression](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ridge_path.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lasso and Ridge Path Diagrams](images/lasso_ridge_path.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### ¿Cómo elegir entre la regresión de Lasso y la regresión de Ridge? **\n",
    "\n",
    "- Se prefiere la regresión de Lasso si creemos que muchas características son irrelevantes o si preferimos un modelo disperso.\n",
    "- Si el rendimiento del modelo es su principal preocupación, es mejor probar ambos.\n",
    "- La regresión de ElasticNet es una combinación de regresión de Lasso y regresión de ridge.\n",
    "\n",
    "**¿Deberían estandarizarse las caractrísticas?**\n",
    "\n",
    "- Sí, porque de lo contrario, las características se penalizarían simplemente por su escala.\n",
    "- Además, la estandarización evita penalizar la intercepción, lo que no tendría sentido intuitivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### Visualizando la regularización\n",
    "\n",
    "A continuación se muestra una visualización de lo que sucede cuando aplica la regularización. La idea general es que está **restringiendo los valores permitidos de sus coeficientes** a una determinada \"región\". **Dentro de esa región**, desea encontrar los coeficientes que den como resultado el mejor modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lasso and Ridge Coefficient Plots](images/lasso_ridge_coefficients.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "En este diagrama:\n",
    "\n",
    "- Estamos ajustando un modelo de regresión lineal con **dos características**, $x_1$ y $x_2$.\n",
    "- $\\hat\\beta$ representa el conjunto de dos coeficientes, $\\beta_1$ y $\\beta_2$, que minimizan el RSS para el **modelo no regular**.\n",
    "- La regularización restringe las posiciones permitidas de $\\hat\\beta$ a la **región de restricción azul:**\n",
    "    - Para Lasso, esta región es un **diamante** porque restringe el valor absoluto de los coeficientes.\n",
    "    - Para Rifge, esta región es un **círculo** porque restringe el cuadrado de los coeficientes.\n",
    "- El tamaño **de la región azul** está determinado por $\\alpha$, con un $\\alpha$ más pequeño resultando en una región más grande:\n",
    "    - Cuando $\\alpha$ es cero, la región azul es infinitamente grande y, por lo tanto, los tamaños de los coeficientes no están restringidos.\n",
    "    - Cuando aumenta $\\alpha$, la región azul se vuelve cada vez más pequeña.\n",
    "\n",
    "En este caso, $\\hat\\beta$ **no** está dentro de la región de restricción azul. Por lo tanto, necesitamos **mover $\\hat\\beta$ hasta que se cruce con la región azul**, mientras que **aumenta el RSS lo menos posible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Parte 4: Regresión regularizada en scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "- Conjunto de datos de comunidades y delitos del Repositorio de aprendizaje automático de la UCI: [datos](http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data), [diccionario de datos](http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime)\n",
    "- **Objetivo:** Predecir la tasa de delitos violentos para una comunidad dados los datos socioeconómicos y de aplicación de la ley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### Cargar y preparar el conjunto de datos sobre delitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages and functions required\n",
    "import numpy as np # for numerical computations\n",
    "import pandas as pd # for data processing,I/O file operations\n",
    "import matplotlib.pyplot as plt # for visualization of different kinds of plots\n",
    "%matplotlib inline\n",
    "# for matplotlib graphs to be included in the notebook, next to the code\n",
    "import seaborn as sns # for visualization\n",
    "import warnings # to silence warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81440.0</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6096.0</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1        2                    3    4     5     6     7     8     9    \\\n",
       "0    8   NaN      NaN         Lakewoodcity    1  0.19  0.33  0.02  0.90  0.12   \n",
       "1   53   NaN      NaN          Tukwilacity    1  0.00  0.16  0.12  0.74  0.45   \n",
       "2   24   NaN      NaN         Aberdeentown    1  0.00  0.42  0.49  0.56  0.17   \n",
       "3   34   5.0  81440.0  Willingborotownship    1  0.04  0.77  1.00  0.08  0.12   \n",
       "4   42  95.0   6096.0    Bethlehemtownship    1  0.01  0.55  0.02  0.95  0.09   \n",
       "\n",
       "   ...   118   119   120   121   122  123  124   125   126   127  \n",
       "0  ...  0.12  0.26  0.20  0.06  0.04  0.9  0.5  0.32  0.14  0.20  \n",
       "1  ...  0.02  0.12  0.45   NaN   NaN  NaN  NaN  0.00   NaN  0.67  \n",
       "2  ...  0.01  0.21  0.02   NaN   NaN  NaN  NaN  0.00   NaN  0.43  \n",
       "3  ...  0.02  0.39  0.28   NaN   NaN  NaN  NaN  0.00   NaN  0.12  \n",
       "4  ...  0.04  0.09  0.02   NaN   NaN  NaN  NaN  0.00   NaN  0.03  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data'\n",
    "crime = pd.read_csv(url, header=None, na_values=['?'])\n",
    "crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1994.000000\n",
       "mean        0.237979\n",
       "std         0.232985\n",
       "min         0.000000\n",
       "25%         0.070000\n",
       "50%         0.150000\n",
       "75%         0.330000\n",
       "max         1.000000\n",
       "Name: 127, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining the response variable\n",
    "crime[127].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "sns.heatmap(crime.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove categorical features\n",
    "crime.drop([0, 1, 2, 3, 4], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with any missing values\n",
    "crime.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "sns.heatmap(crime.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 123)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkng the shape\n",
    "crime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = crime.drop(127, axis=1)\n",
    "y = crime[127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERCEPT :  0.992212528758639\n",
      "CO-EFFICIENT :  [-3.93018330e+00  7.31324716e-01 -3.01181421e-01 -2.96634778e-01\n",
      " -1.83170801e-01  2.81575284e-01 -1.48744636e+00 -4.84695533e-01\n",
      "  1.24104896e+00 -5.32282788e-01  4.64331123e+00 -1.17079618e-01\n",
      "  1.04229108e+00  1.36950901e-01 -3.12434116e-01 -1.16489196e+00\n",
      "  5.37252913e-01  7.49655606e-01 -8.02500871e-02  8.42449509e-01\n",
      " -1.98951720e-01 -3.17193999e-01 -4.31217869e-01  1.19357660e-01\n",
      " -1.83148129e-01  2.11602690e-01 -1.57441950e-01 -1.03051105e+00\n",
      "  1.49628176e+00  1.86093900e-01 -1.12289917e+00 -1.13107576e-02\n",
      "  1.22670519e-01  1.46348876e-01 -1.64172731e-01 -3.73690589e-02\n",
      "  1.92733806e-01  4.34808503e-01  2.32870361e+00 -5.15176228e-01\n",
      "  2.64683754e+00 -5.48075999e+00  9.63873430e-01 -1.15021921e+00\n",
      " -1.15575665e+00  1.10543276e+00  2.41469970e-01 -6.32209680e-01\n",
      "  6.01741978e-01  8.37645340e-02  1.05006759e-01 -2.58807800e-01\n",
      "  5.31513493e-01 -8.57090632e-01 -3.29684470e-01  6.61114510e-01\n",
      " -5.61884511e-01  6.27806334e-01  2.79848006e+00 -3.84376383e+00\n",
      "  6.63383105e-01  2.32831180e-01  1.15525109e+00 -2.19222321e+00\n",
      " -1.92937779e+00  1.06762622e+00 -5.01393215e-01 -1.64350691e+00\n",
      "  8.32031485e-01  5.37236526e-01  4.71215083e-02  1.63071151e-01\n",
      "  1.69213367e-01  2.37904894e+00 -6.07853084e-02  8.66170663e-02\n",
      " -1.22137425e-01 -1.33214743e-02 -9.10806303e-02 -4.95926018e-01\n",
      " -3.95077878e-01  2.10098688e-01 -7.87407370e-01 -7.33504750e-02\n",
      " -5.26665903e-03  1.32948476e+00 -6.75588810e-01 -3.80850714e-02\n",
      " -2.36755772e-01 -5.33694434e-02  2.49902747e-01  1.26616251e+00\n",
      " -3.81256219e-01 -4.90756320e-02  1.34437151e-02  3.03344698e-01\n",
      " -6.62671259e-01 -4.80322445e+01 -2.79029053e-01 -1.18121012e-01\n",
      " -1.14722614e-01  1.76167904e-01  8.81716178e-02  4.85437648e+01\n",
      " -4.68216237e-02 -3.35980437e-02  2.10370431e-01  2.57465906e-01\n",
      "  1.74268864e-01 -5.58776973e-01 -2.35432646e-01  3.77183848e-03\n",
      "  3.02620708e-02  8.18559046e-02  1.21865592e-02 -1.82516177e-01\n",
      "  1.85129424e-01  5.32261788e-01  3.97216221e-03  1.24490041e-02\n",
      " -4.86500053e-02 -4.77213525e-01]\n"
     ]
    }
   ],
   "source": [
    "print (\"INTERCEPT : \",linreg.intercept_)\n",
    "print (\"CO-EFFICIENT : \",linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8752096141514378"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions train\n",
    "y_pred_train = linreg.predict(X_train)\n",
    "r2_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.19704456295409856\n",
      "\n",
      "\n",
      "mean_absolute_error : 0.1672515582488828\n",
      "\n",
      "\n",
      "mean_squared_error :  0.04986345422693358\n",
      "\n",
      "\n",
      "root_mean_squared_error :  0.22330126337961811\n"
     ]
    }
   ],
   "source": [
    "# calculate R^2 value, MAE, MSE, RMSE\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "MSE es más popular que MAE porque MSE \"elimina\" errores mayores. Pero RMSE es incluso mejor que MSE porque RMSE se puede interpretar en las unidades \"y\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### Ridge regression\n",
    "\n",
    "- Documentación de [Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "- **alpha:** debe ser positivo, aumentar para una mayor regularización\n",
    "- **normalizar:** escala las características (sin usar StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.197044562957847\n",
      "\n",
      "\n",
      "mean_absolute_error : 0.1672515582482433\n",
      "\n",
      "\n",
      "mean_squared_error :  0.0498634542267008\n",
      "\n",
      "\n",
      "root_mean_squared_error :  0.2233012633790969\n"
     ]
    }
   ],
   "source": [
    "# alpha=0 is equivalent to linear regression\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg = Ridge(alpha=0, normalize=True)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "# calculate R^2 value, MAE, MSE, RMSE\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.5347697501566352\n",
      "\n",
      "\n",
      "mean_absolute_error : 0.12769772972161875\n",
      "\n",
      "\n",
      "mean_squared_error :  0.028890753082631365\n",
      "\n",
      "\n",
      "root_mean_squared_error :  0.16997280100837123\n"
     ]
    }
   ],
   "source": [
    "# try alpha=0.1\n",
    "ridgereg = Ridge(alpha=0.1, normalize=True)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "\n",
    "# calculate R^2 value, MAE, MSE, RMSE\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.77226675e-03  2.26721774e-02  4.98857382e-02 -6.70174168e-02\n",
      " -1.83566112e-02  5.26888536e-02  1.17689929e-02 -5.72468914e-02\n",
      "  1.52761058e-03  4.29131248e-02  1.04586550e-04 -1.85621890e-02\n",
      "  5.07008262e-02 -9.63941391e-02 -1.58499805e-01 -3.28082329e-01\n",
      " -1.43015949e-02  8.97253556e-02 -1.10520025e-01  8.02961453e-02\n",
      " -2.01498712e-02  7.77242382e-03 -8.07823610e-02 -1.39148634e-01\n",
      " -1.19008810e-02  1.00148033e-01  3.61850806e-02 -9.71628046e-02\n",
      "  6.94268658e-02 -8.81688130e-02 -9.79415666e-02 -4.99145470e-03\n",
      "  1.28541873e-01 -4.15102106e-02 -1.35952164e-01  4.09752240e-02\n",
      "  7.00727085e-02 -1.86859042e-02  5.95401646e-02  6.28621417e-02\n",
      " -3.91478791e-02  8.48551263e-03  7.31545217e-02 -1.28265573e-01\n",
      " -1.22240655e-01 -7.02441332e-02 -7.10900893e-02 -6.33671556e-02\n",
      "  1.01095274e-01 -5.22454503e-02  1.15465301e-01 -7.35016006e-02\n",
      " -4.79847841e-03 -1.10878367e-01  6.49567154e-02  4.12339751e-02\n",
      " -1.06606017e-02  1.32494298e-03  1.81063822e-02 -1.85567810e-03\n",
      " -1.32904914e-02  3.94493914e-02  1.00675199e-02 -6.17632878e-03\n",
      " -6.48193614e-03  3.75746635e-02 -1.11798761e-01  3.89474904e-02\n",
      "  3.84145367e-02  2.27608462e-01  2.56008069e-02  2.07966422e-02\n",
      "  4.30938894e-02  6.63025655e-02 -1.02913734e-02  3.78084421e-02\n",
      " -1.81938584e-02  2.67122511e-02 -5.91571726e-02 -1.11215117e-02\n",
      " -1.39886745e-02 -8.38803903e-03 -1.44263720e-01  5.42415176e-02\n",
      "  2.27326417e-02  1.05911835e-01 -1.09837108e-01 -6.00233055e-02\n",
      " -9.42476546e-02  9.20602987e-02  1.52695617e-01  3.12870498e-02\n",
      " -7.89722447e-02  3.30793696e-02 -4.49652275e-02  3.73987698e-02\n",
      " -3.92834764e-02  2.44368715e-02  2.39059642e-02 -4.36748260e-03\n",
      "  7.88355114e-03  3.52470803e-02  8.66981935e-02  2.80030258e-02\n",
      " -1.27168295e-01 -1.18490708e-02  9.56179076e-03  3.26964467e-02\n",
      "  8.95863094e-02 -3.18437162e-02 -2.36547537e-02  4.67552852e-02\n",
      " -2.69161523e-03  3.60806144e-02 -4.33459917e-02 -5.49197916e-02\n",
      "  1.14859081e-01  6.18430307e-02 -9.01777227e-03  4.93420155e-02\n",
      " -7.56394250e-02 -5.68112163e-02]\n"
     ]
    }
   ],
   "source": [
    "# examing the coefficients\n",
    "print(ridgereg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "- [RidgeCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html): ridge regression con validación cruzada incorporada del parámetro alfa (LO VEREMOS EN UN SIGUIENTE NOTEBOOK)\n",
    "- **alfas:** matriz de valores alfa para probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an array of alpha values\n",
    "alpha_range = 10.**np.arange(-2, 3)\n",
    "alpha_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the best alpha with RidgeCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "ridgeregcv = RidgeCV(alphas=alpha_range, normalize=True, scoring='r2')\n",
    "ridgeregcv.fit(X_train, y_train)\n",
    "ridgeregcv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.5318623469518302\n",
      "\n",
      "\n",
      "mean_absolute_error : 0.13256644483823612\n",
      "\n",
      "\n",
      "mean_squared_error :  0.029071302537723664\n",
      "\n",
      "\n",
      "root_mean_squared_error :  0.17050308659295194\n"
     ]
    }
   ],
   "source": [
    "# predict method uses the best alpha value\n",
    "y_pred = ridgeregcv.predict(X_test)\n",
    "# calculate R^2 value, MAE, MSE, RMSE\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### Lasso regression\n",
    "\n",
    "- Documentación de [Lasso](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "- **alpha:** debe ser positivo, aumentar para una mayor regularización\n",
    "- **normalizar:** escala las características (sin usar StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.         -0.25339884  0.          0.\n",
      "  0.         -0.         -0.          0.          0.          0.\n",
      " -0.         -0.         -0.         -0.17865705  0.          0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.02230294\n",
      " -0.          0.          0.          0.          0.0998841  -0.\n",
      "  0.         -0.          0.01893786 -0.         -0.03169217  0.\n",
      "  0.         -0.          0.11479343  0.          0.          0.\n",
      "  0.         -0.16845012 -0.27294066 -0.         -0.         -0.\n",
      " -0.          0.          0.          0.          0.         -0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.          0.          0.02709397 -0.          0.\n",
      " -0.         -0.          0.          0.          0.          0.\n",
      "  0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.         -0.         -0.          0.00233805\n",
      "  0.15404259  0.         -0.         -0.          0.         -0.\n",
      "  0.          0.         -0.          0.          0.          0.\n",
      "  0.03385823  0.         -0.0136048  -0.          0.          0.\n",
      "  0.01441679  0.          0.          0.         -0.          0.\n",
      " -0.         -0.          0.04851355  0.         -0.          0.0220025\n",
      " -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# try alpha=0.001 and examine coefficients\n",
    "from sklearn.linear_model import Lasso\n",
    "lassoreg = Lasso(alpha=0.001, normalize=True)\n",
    "lassoreg.fit(X_train, y_train)\n",
    "print(lassoreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.         -0.04214088  0.          0.\n",
      "  0.          0.          0.         -0.          0.          0.\n",
      " -0.         -0.         -0.         -0.         -0.          0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.          0.          0.          0.\n",
      "  0.         -0.          0.         -0.         -0.          0.\n",
      "  0.         -0.          0.          0.          0.          0.\n",
      "  0.         -0.         -0.29715868 -0.         -0.         -0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.          0.          0.         -0.          0.\n",
      " -0.         -0.          0.          0.         -0.          0.\n",
      "  0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.         -0.         -0.          0.\n",
      "  0.          0.          0.         -0.          0.          0.\n",
      "  0.          0.         -0.          0.          0.          0.\n",
      "  0.          0.         -0.         -0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.          0.\n",
      " -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# try alpha=0.01 and examine coefficients\n",
    "lassoreg = Lasso(alpha=0.01, normalize=True)\n",
    "lassoreg.fit(X_train, y_train)\n",
    "print(lassoreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.3241322659149898\n",
      "\n",
      "\n",
      "mean_absolute_error : 0.16889755277533727\n",
      "\n",
      "\n",
      "mean_squared_error :  0.04197132028397072\n",
      "\n",
      "\n",
      "root_mean_squared_error :  0.20486903202770965\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE (for alpha=0.01)\n",
    "y_pred = lassoreg.predict(X_test)\n",
    "# calculate MAE, MSE, RMSE\n",
    "# calculate R^2 value, MAE, MSE, RMSE\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "- [LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html): Lasso regression con validación cruzada incorporada del parámetro alfa\n",
    "- **n_ alfas:** número de valores alfa (elegidos automáticamente) para probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha :  0.0016878682947072093\n"
     ]
    }
   ],
   "source": [
    "# select the best alpha with LassoCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "lassoregcv = LassoCV(n_alphas=100, normalize=True, random_state=1)\n",
    "lassoregcv.fit(X_train, y_train)\n",
    "print('alpha : ',lassoregcv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.         -0.26320105  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.         -0.         -0.         -0.1285917   0.          0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.          0.         -0.          0.          0.11511909  0.\n",
      "  0.         -0.          0.         -0.         -0.          0.\n",
      "  0.         -0.          0.04667596  0.          0.          0.08875875\n",
      "  0.         -0.09735466 -0.3276063  -0.         -0.         -0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.          0.          0.         -0.          0.\n",
      " -0.         -0.          0.          0.          0.          0.\n",
      "  0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.         -0.         -0.          0.\n",
      "  0.14776487  0.         -0.         -0.         -0.         -0.\n",
      "  0.          0.         -0.          0.          0.          0.\n",
      "  0.00639313  0.         -0.         -0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.          0.\n",
      "  0.          0.          0.02772175  0.         -0.          0.\n",
      " -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# examine the coefficients\n",
    "print(lassoregcv.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.5506049113488305\n",
      "\n",
      "\n",
      "mean_absolute_error : 0.13416628182873494\n",
      "\n",
      "\n",
      "mean_squared_error :  0.0279073911189985\n",
      "\n",
      "\n",
      "root_mean_squared_error :  0.16705505415580368\n"
     ]
    }
   ],
   "source": [
    "# predict method uses the best alpha value\n",
    "y_pred = lassoregcv.predict(X_test)\n",
    "# calculate R^2 value, MAE, MSE, RMSE\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "# Comparación de modelos lineales regularizados con modelos lineales no regularizados\n",
    "\n",
    "**Ventajas de los modelos lineales regularizados sobre los lineales:**\n",
    "\n",
    "- Mejor performance\n",
    "- La regularización L1 realiza la selección automática de características\n",
    "- Útil para problemas de alta dimensión (p > n)\n",
    "\n",
    "**Desventajas de los modelos lineales regularizados sobre los lineales:**\n",
    "\n",
    "- Se requiere afinación (tunning).\n",
    "- Se recomienda el escalado de variables.\n",
    "- Menos interpretable (debido a la escala de características)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
